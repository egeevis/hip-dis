import os
import io
import json
from typing import List, Dict, Any

import streamlit as st

openai_key = st.sidebar.text_input(
    "OpenAI API Key",
    type="password",
    value=os.getenv("OPENAI_API_KEY", st.secrets.get("OPENAI_API_KEY", "")),
    key="openai_api_key_input"
)



# Optional deps (add to requirements.txt):
# streamlit
# python-docx
# PyPDF2
# openai>=1.30.0
# jsonschema

try:
    from docx import Document
except Exception:
    Document = None

try:
    import PyPDF2
except Exception:
    PyPDF2 = None

try:
    from jsonschema import validate as jsonschema_validate
except Exception:
    def jsonschema_validate(instance, schema):
        return True

try:
    from openai import OpenAI
except Exception:
    OpenAI = None

st.set_page_config(page_title="Hiperaktivist â€“ KullanÄ±cÄ± Analiz Sistemi", page_icon="ğŸ§©", layout="wide")
st.title("Hiperaktivist â€¢ DÄ±ÅŸ Sistem: KullanÄ±cÄ± Analiz Motoru")
st.caption("20 soruya verilen yanÄ±tlarÄ±, EÄŸitim iÃ§eriÄŸi + Teknik & YÃ¶ntemler'e sadÄ±k kalarak analiz eder.")

# ------------------------------
# Helpers
# ------------------------------

def read_file(file) -> str:
    name = file.name.lower()
    if name.endswith(".txt") or name.endswith(".md"):
        return file.read().decode("utf-8", errors="ignore")
    if name.endswith(".docx"):
        if not Document:
            return "(python-docx yok â€“ requirements'e ekleyin)"
        buf = io.BytesIO(file.read())
        doc = Document(buf)
        return "\n".join([p.text for p in doc.paragraphs])
    if name.endswith(".pdf"):
        if not PyPDF2:
            return "(PyPDF2 yok â€“ requirements'e ekleyin)"
        buf = io.BytesIO(file.read())
        reader = PyPDF2.PdfReader(buf)
        pages = []
        for p in reader.pages:
            try:
                pages.append(p.extract_text() or "")
            except Exception:
                pages.append("")
        return "\n".join(pages)
    try:
        return file.read().decode("utf-8", errors="ignore")
    except Exception:
        return ""

ANALYSIS_SCHEMA: Dict[str, Any] = {
    "type": "object",
    "properties": {
        "meta": {
            "type": "object",
            "properties": {
                "education_title": {"type": "string"},
                "num_answers": {"type": "integer"},
                "language": {"type": "string"},
            },
            "required": ["education_title", "num_answers", "language"],
        },
        "themes": {"type": "array", "items": {"type": "string"}},
        "strengths": {"type": "array", "items": {"type": "string"}},
        "growth_areas": {"type": "array", "items": {"type": "string"}},
        "micro_actions": {"type": "array", "items": {"type": "string"}},
        "ga_style_narrative": {"type": "string"},
        "safety_notes": {"type": "string"},
    },
    "required": ["meta", "themes", "strengths", "growth_areas", "micro_actions", "ga_style_narrative"],
}

SYSTEM_PROMPT = """
Sen, Hiperaktivist markasÄ±nÄ±n sunduÄŸu kiÅŸisel geliÅŸim eÄŸitimleri iÃ§in Ã¶zel olarak geliÅŸtirilmiÅŸ DÄ±ÅŸ Sistem analiz yapay zekÃ¢sÄ±sÄ±n.

AmacÄ±n:
- KullanÄ±cÄ±nÄ±n 20 soruya verdiÄŸi yanÄ±tlarÄ±, ilgili eÄŸitim iÃ§eriÄŸi ve GA'nÄ±n Teknik & YÃ¶ntemleri doÄŸrultusunda iÅŸleyerek derin, kiÅŸisel ve anlamlÄ± bir geliÅŸim analizi sunmak.
- Ã‡Ä±ktÄ± tek parÃ§a, akÄ±cÄ± ve zengin bir metin olmalÄ±. Madde listeleri yerine, bÃ¼tÃ¼nlÃ¼klÃ¼ bir anlatÄ±m iÃ§inde kiÅŸisel gÃ¶zlemler, duygusal farkÄ±ndalÄ±k, eÄŸitimden gelen ana fikirler ve uygulanabilir Ã¶neriler harmanlanmalÄ±.
- Metin GA metodolojisine sadÄ±k, yargÄ±sÄ±z, empatik, gÃ¼venli ve profesyonel bir Ã¼slupta olmalÄ±.
- Nihai hedef, kullanÄ±cÄ±nÄ±n eÄŸitimden aldÄ±ÄŸÄ± deÄŸeri gÃ¼nlÃ¼k yaÅŸamÄ±na entegre edebilmesini kolaylaÅŸtÄ±rmaktÄ±r.

Kurallar:
- Kesinlikle â€œtemalar, gÃ¼Ã§lÃ¼ alanlar, geliÅŸim alanlarÄ±â€ gibi baÅŸlÄ±klar verme.
- Metin, kullanÄ±cÄ± yanÄ±tlarÄ±ndaki ipuÃ§larÄ±nÄ± doÄŸrudan yansÄ±tsÄ±n, kiÅŸiselleÅŸtirilmiÅŸ hissettirsin.
- Uygulanabilir Ã¶neriler metnin iÃ§ine doÄŸal biÃ§imde yedirilsin.
- Gerekiyorsa gÃ¼venlik / kriz uyarÄ±larÄ±nÄ± metnin sonunda ekle.
""".strip()


USER_TEMPLATE = """
# EÄÄ°TÄ°M Ã–ZETÄ°
{education_summary}

# TEKNÄ°K & YÃ–NTEMLER Ã–ZETÄ°
{techniques_summary}

# SORULAR
{questions_json}

# KULLANICI YANITLARI
{answers_json}

# JSON ÅEMA
{json_schema}
""".strip()

# ------------------------------
# Sidebar settings
# ------------------------------
st.sidebar.header("Ayarlar")
openai_key = st.sidebar.text_input(
    "OpenAI API Key",
    type="password",
    value=os.getenv("OPENAI_API_KEY", st.secrets.get("OPENAI_API_KEY", "")),
    key="openai_api_key_sidebar"
)
model = st.sidebar.text_input("Model", value="gpt-4o-mini")
language = st.sidebar.selectbox("Dil", ["TÃ¼rkÃ§e", "English"], index=0)
max_actions = st.sidebar.slider("Mikro eylem sayÄ±sÄ±", 3, 10, 5)
temperature = st.sidebar.slider("Temperature", 0.0, 1.0, 0.3, 0.05)

client = None
if openai_key and OpenAI:
    try:
        client = OpenAI(api_key=openai_key)
    except Exception as e:
        st.sidebar.error(f"OpenAI istemcisi baÅŸlatÄ±lamadÄ±: {e}")
# ------------------------------
# Inputs
# ------------------------------
left, right = st.columns(2)
with left:
    q_file = st.file_uploader("Soru Seti (JSON)", type=["json"], key="qjson")
with right:
    edu_file = st.file_uploader("EÄŸitim DosyasÄ± (docx/pdf/txt/md)", type=["docx", "pdf", "txt", "md"], key="edu")

ty_file = st.file_uploader("Teknik & YÃ¶ntemler (docx/pdf/txt/md)", type=["docx", "pdf", "txt", "md"], key="ty")

questions = []
q_meta = {}
if q_file:
    try:
        raw = json.loads(q_file.read().decode("utf-8"))
        questions = raw.get("questions", [])
        q_meta = raw.get("meta", {})
    except Exception as e:
        st.error(f"Soru JSON okunamadÄ±: {e}")

# Render dynamic form
st.markdown("---")
st.subheader("ğŸ“ KullanÄ±cÄ± YanÄ±tlarÄ±")
answers: List[Dict[str, Any]] = []
if questions:
    for i, q in enumerate(questions, start=1):
        qid = q.get("id", str(i))
        label = q.get("question", f"Soru {i}")
        ans = st.text_area(label, key=f"ans_{qid}", height=120)
        answers.append({"id": qid, "answer": ans})
else:
    st.info("LÃ¼tfen soru seti JSON'unu yÃ¼kleyin (Ã¶r. sorular_1.json).")

# Show previews for context docs
edu_text = ""
tech_text = ""
if edu_file:
    edu_text = read_file(edu_file)
    with st.expander("EÄŸitim Metni (Ã¶nizleme)", expanded=False):
        st.text_area("EÄŸitim metni Ã¶nizleme", value=edu_text[:6000], height=200, label_visibility="collapsed")
if ty_file:
    tech_text = read_file(ty_file)
    with st.expander("Teknik & YÃ¶ntemler (Ã¶nizleme)", expanded=False):
        st.text_area("Teknik & YÃ¶ntemler Ã¶nizleme", value=tech_text[:6000], height=200, label_visibility="collapsed")

# ------------------------------
# LLM helpers
# ------------------------------

def summarize_text(client, model: str, text: str, label: str) -> str:
    prompt = f"Metni 10-12 maddeyle kÄ±sa, Ã¶z ve bilgi kaybÄ± olmadan Ã¶zetle. BaÅŸlÄ±k: {label}.\n\nMetin:\n{text[:12000]}"
    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "KÄ±sa ve bilgi kaybÄ± olmadan Ã¶zetleyen bir yardÄ±mcÄ± yazarsÄ±n."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"(Ã–zetlenemedi: {e})"


def generate_analysis(client, model: str, system_prompt: str, user_prompt: str, temperature: float = 0.3) -> Dict[str, Any]:
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=temperature,
        response_format={"type": "json_object"},
    )
    content = resp.choices[0].message.content
    try:
        data = json.loads(content)
    except Exception:
        data = {"raw": content}
    return data

# ------------------------------
# Generate
# ------------------------------
c1, c2, c3 = st.columns([1.2,1,1])
with c1:
    can_generate = client and questions and any(a.get("answer") for a in answers) and (edu_text and tech_text)
    if st.button("ğŸ§  Analizi Ãœret", type="primary", use_container_width=True, disabled=not can_generate):
        with st.spinner("Analiz hazÄ±rlanÄ±yorâ€¦"):
            edu_summary = summarize_text(client, model, edu_text, "EÄŸitim Ã–zeti")
            ty_summary = summarize_text(client, model, tech_text, "Teknik & YÃ¶ntemler Ã–zeti")

            # Trim micro action count in schema hint (model uses it in narrative)
            schema = ANALYSIS_SCHEMA.copy()

            system_prompt = SYSTEM_PROMPT
            user_prompt = USER_TEMPLATE.format(
                education_summary=edu_summary,
                techniques_summary=ty_summary,
                questions_json=json.dumps(questions, ensure_ascii=False),
                answers_json=json.dumps(answers, ensure_ascii=False),
                json_schema=json.dumps(schema, ensure_ascii=False),
            )

            data = generate_analysis(client, model, system_prompt, user_prompt, temperature)

            # Attach meta
            data.setdefault("meta", {})
            data["meta"].setdefault("education_title", q_meta.get("education_title", "EÄŸitim"))
            data["meta"]["num_answers"] = len([a for a in answers if a.get("answer")])
            data["meta"]["language"] = language

            st.session_state["analysis_data"] = data
            st.session_state["analysis_text"] = None

with c2:
    if st.session_state.get("analysis_data"):
        if st.button("â¬‡ï¸ JSON indir", use_container_width=True):
            st.download_button(
                "Ä°ndir (analysis.json)",
                data=json.dumps(st.session_state["analysis_data"], ensure_ascii=False, indent=2),
                file_name="analysis.json",
                mime="application/json",
            )
with c3:
    pass

# ------------------------------
# Show output
# ------------------------------
if st.session_state.get("analysis_data"):
    st.markdown("---")
    st.subheader("ğŸ“ Analiz Sonucu")
    data = st.session_state["analysis_data"]

    # Validate (best-effort)
    try:
        jsonschema_validate(data, ANALYSIS_SCHEMA)
    except Exception as e:
        st.warning(f"Åema doÄŸrulamasÄ± uyarÄ±sÄ±: {e}")

    # Render
    meta = data.get("meta", {})
    st.write(f"**EÄŸitim:** {meta.get('education_title', 'EÄŸitim')} Â· **YanÄ±t sayÄ±sÄ±:** {meta.get('num_answers', 0)}")

    cols = st.columns(3)
    with cols[0]:
        st.markdown("**Temalar**")
        for t in data.get("themes", []):
            st.write("â€¢", t)
    with cols[1]:
        st.markdown("**GÃ¼Ã§lÃ¼ Alanlar**")
        for t in data.get("strengths", []):
            st.write("â€¢", t)
    with cols[2]:
        st.markdown("**GeliÅŸim AlanlarÄ±**")
        for t in data.get("growth_areas", []):
            st.write("â€¢", t)

    st.markdown("**Mikro Eylemler (Ã¶neri)**")
    for i, a in enumerate(data.get("micro_actions", []), start=1):
        st.write(f"{i}. {a}")

    st.markdown("**GA Ãœslubunda AnlatÄ±**")
    st.text_area("AnlatÄ±", value=data.get("ga_style_narrative", ""), height=300)

    if data.get("safety_notes"):
        st.info(data.get("safety_notes"))

    # Exports
    export_cols = st.columns(2)
    with export_cols[0]:
        pretty = json.dumps(data, ensure_ascii=False, indent=2)
        st.download_button("ğŸ“¥ analysis.json", data=pretty, file_name="analysis.json", mime="application/json")
    with export_cols[1]:
        md = [
            f"# {meta.get('education_title','EÄŸitim')} â€“ KiÅŸisel Analiz",
            "## Temalar",
            *[f"- {t}" for t in data.get("themes", [])],
            "\n## GÃ¼Ã§lÃ¼ Alanlar",
            *[f"- {t}" for t in data.get("strengths", [])],
            "\n## GeliÅŸim AlanlarÄ±",
            *[f"- {t}" for t in data.get("growth_areas", [])],
            "\n## Mikro Eylemler",
            *[f"- {t}" for t in data.get("micro_actions", [])],
            "\n## GA Ãœslubunda AnlatÄ±\n",
            data.get("ga_style_narrative", ""),
            "\n\n---\nOtomatik Ã¼retildi: Hiperaktivist Analiz Sistemi",
        ]
        md_text = "\n".join(md)
        st.download_button("ğŸ“ Markdown indir", data=md_text, file_name="analysis.md", mime="text/markdown")

# ------------------------------
# Footer
# ------------------------------
st.markdown(
    """
---
**KullanÄ±m AkÄ±ÅŸÄ±:**  
1) Ä°Ã§ sistemden Ã¼rettiÄŸiniz `sorular_*.json` dosyasÄ±nÄ± yÃ¼kleyin.  
2) EÄŸitime ait `EÄŸitim` ve `Teknik & YÃ¶ntemler` dosyalarÄ±nÄ± yÃ¼kleyin.  
3) KullanÄ±cÄ± yanÄ±tlarÄ±nÄ± girin / yapÄ±ÅŸtÄ±rÄ±n.  
4) **Analizi Ãœret** dÃ¼ÄŸmesine tÄ±klayÄ±n; JSON ve Markdown Ã§Ä±ktÄ±larÄ± indirin.

**Notlar**  
â€¢ Ã‡Ä±ktÄ± GA Ã¼slubuna ve dokÃ¼manlarÄ±nÄ±za sadÄ±k kalarak Ã¼retilir.  
â€¢ JSON ÅŸemasÄ± sayesinde raporlarÄ±nÄ±z tutarlÄ± yapÄ±dadÄ±r.  
â€¢ Gerekirse `analysis.json` iÃ§inden mÃ¼ÅŸteri raporu PDFâ€™leri Ã¼retebilirsiniz (ayrÄ± bir adÄ±mda).
"""
)
