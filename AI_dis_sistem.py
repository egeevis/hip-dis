import os
import io
import json
from typing import List, Dict, Any

import streamlit as st

# ------------------------------
# API Key
# ------------------------------
openai_key = st.sidebar.text_input(
    "OpenAI API Key",
    type="password",
    value=os.getenv("OPENAI_API_KEY", st.secrets.get("OPENAI_API_KEY", "")),
    key="openai_api_key_input"
)

# Optional deps
try:
    from docx import Document
except Exception:
    Document = None

try:
    import PyPDF2
except Exception:
    PyPDF2 = None

try:
    from jsonschema import validate as jsonschema_validate
except Exception:
    def jsonschema_validate(instance, schema):
        return True

try:
    from openai import OpenAI
except Exception:
    OpenAI = None

# ------------------------------
# Streamlit UI Config
# ------------------------------
st.set_page_config(page_title="Hiperaktivist â€“ KullanÄ±cÄ± Analiz Sistemi", page_icon="ðŸ§©", layout="wide")
st.title("Hiperaktivist â€¢ DÄ±ÅŸ Sistem: KullanÄ±cÄ± Analiz Motoru")
st.caption("20 soruya verilen yanÄ±tlarÄ±, EÄŸitim iÃ§eriÄŸi + Teknik & YÃ¶ntemler'e sadÄ±k kalarak tek parÃ§a sistem analizi Ã¼retir.")

# ------------------------------
# Helpers
# ------------------------------
def read_file(file) -> str:
    name = file.name.lower()
    if name.endswith(".txt") or name.endswith(".md"):
        return file.read().decode("utf-8", errors="ignore")
    if name.endswith(".docx"):
        if not Document:
            return "(python-docx yok â€“ requirements'e ekleyin)"
        buf = io.BytesIO(file.read())
        doc = Document(buf)
        return "\n".join([p.text for p in doc.paragraphs])
    if name.endswith(".pdf"):
        if not PyPDF2:
            return "(PyPDF2 yok â€“ requirements'e ekleyin)"
        buf = io.BytesIO(file.read())
        reader = PyPDF2.PdfReader(buf)
        pages = []
        for p in reader.pages:
            try:
                pages.append(p.extract_text() or "")
            except Exception:
                pages.append("")
        return "\n".join(pages)
    try:
        return file.read().decode("utf-8", errors="ignore")
    except Exception:
        return ""

# ------------------------------
# JSON Schema (Simplified)
# ------------------------------
ANALYSIS_SCHEMA = {
    "type": "object",
    "properties": {
        "meta": {
            "type": "object",
            "properties": {
                "education_title": {"type": "string"},
                "num_answers": {"type": "integer"},
                "language": {"type": "string"},
            },
            "required": ["education_title", "num_answers", "language"],
        },
        "ga_style_narrative": {"type": "string"},
        "safety_notes": {"type": "string"},
    },
    "required": ["meta", "ga_style_narrative"],
}

# ------------------------------
# Prompts
# ------------------------------
SYSTEM_PROMPT = """
Sen, Hiperaktivist markasÄ±nÄ±n sunduÄŸu kiÅŸisel geliÅŸim eÄŸitimleri iÃ§in Ã¶zel olarak geliÅŸtirilmiÅŸ bir "KullanÄ±cÄ± YanÄ±tlarÄ± Analiz UzmanÄ±"sÄ±n.

GÃ¶revin:
- KullanÄ±cÄ±nÄ±n 20 soruya verdiÄŸi yanÄ±tlarÄ± dikkatle inceleyip, **EÄŸitim Ã–zeti** ve **Teknik & YÃ¶ntemler Ã–zeti** bÃ¶lÃ¼mlerinde verilen bilgiler doÄŸrultusunda bÃ¼tÃ¼nlÃ¼klÃ¼, kiÅŸiselleÅŸtirilmiÅŸ ve anlamlÄ± bir geliÅŸim analizi sunmak.
- Analiz yaparken **mutlaka EÄŸitim Ã–zeti ve Teknik & YÃ¶ntemler Ã–zeti'ne sadÄ±k kal**. Bu iÃ§eriklerin dÄ±ÅŸÄ±nda varsayÄ±mlarda bulunma veya baÄŸlam dÄ±ÅŸÄ± yorum yapma.
- Ã‡Ä±ktÄ± TEK BÄ°R uzun metin olacak, baÅŸlÄ±k veya madde listesi olmayacak.
- AnlatÄ±m akÄ±cÄ±, empatik, yargÄ±sÄ±z ve profesyonel olmalÄ±.
- KullanÄ±cÄ±nÄ±n yanÄ±tlarÄ±ndaki duygusal ton, ihtiyaÃ§lar, farkÄ±ndalÄ±klar ve olasÄ± zorluklar analiz iÃ§inde doÄŸal biÃ§imde yer almalÄ±.
- Analizde, eÄŸitimde verilen bilgiler ile kullanÄ±cÄ±nÄ±n mevcut durumunu eÅŸleÅŸtirerek yorum yap.
- Gerekiyorsa gÃ¼venlik / kriz uyarÄ±larÄ±nÄ± metnin sonunda ekle.
- Nihai hedef, kullanÄ±cÄ±nÄ±n eÄŸitimden aldÄ±ÄŸÄ± deÄŸeri gÃ¼nlÃ¼k yaÅŸamÄ±na entegre edebilmesini kolaylaÅŸtÄ±rmaktÄ±r.
""".strip()


USER_TEMPLATE = """
# EÄžÄ°TÄ°M Ã–ZETÄ°
{education_summary}

# TEKNÄ°K & YÃ–NTEMLER Ã–ZETÄ°
{techniques_summary}

# SORULAR
{questions_json}

# KULLANICI YANITLARI
{answers_json}

# JSON ÅžEMA
{json_schema}
""".strip()

# ------------------------------
# Sidebar
# ------------------------------
st.sidebar.header("Ayarlar")
openai_key = st.sidebar.text_input(
    "OpenAI API Key",
    type="password",
    value=os.getenv("OPENAI_API_KEY", st.secrets.get("OPENAI_API_KEY", "")),
    key="openai_api_key_sidebar"
)
model = st.sidebar.text_input("Model", value="gpt-4o-mini")
language = st.sidebar.selectbox("Dil", ["TÃ¼rkÃ§e", "English"], index=0)
temperature = st.sidebar.slider("Temperature", 0.0, 1.0, 0.3, 0.05)

client = None
if openai_key and OpenAI:
    try:
        client = OpenAI(api_key=openai_key)
    except Exception as e:
        st.sidebar.error(f"OpenAI istemcisi baÅŸlatÄ±lamadÄ±: {e}")

# ------------------------------
# Inputs
# ------------------------------
left, right = st.columns(2)
with left:
    q_file = st.file_uploader("Soru Seti (JSON)", type=["json"], key="qjson")
with right:
    edu_file = st.file_uploader("EÄŸitim DosyasÄ± (docx/pdf/txt/md)", type=["docx", "pdf", "txt", "md"], key="edu")

ty_file = st.file_uploader("Teknik & YÃ¶ntemler (docx/pdf/txt/md)", type=["docx", "pdf", "txt", "md"], key="ty")

questions = []
q_meta = {}
if q_file:
    try:
        raw = json.loads(q_file.read().decode("utf-8"))
        questions = raw.get("questions", [])
        q_meta = raw.get("meta", {})
    except Exception as e:
        st.error(f"Soru JSON okunamadÄ±: {e}")

# ------------------------------
# User Answers
# ------------------------------
st.markdown("---")
st.subheader("ðŸ“ KullanÄ±cÄ± YanÄ±tlarÄ±")
answers: List[Dict[str, Any]] = []
if questions:
    for i, q in enumerate(questions, start=1):
        qid = q.get("id", str(i))
        label = q.get("question", f"Soru {i}")
        ans = st.text_area(label, key=f"ans_{qid}", height=120)
        answers.append({"id": qid, "answer": ans})
else:
    st.info("LÃ¼tfen soru seti JSON'unu yÃ¼kleyin.")

# ------------------------------
# Context Docs Preview
# ------------------------------
edu_text = ""
tech_text = ""
if edu_file:
    edu_text = read_file(edu_file)
if ty_file:
    tech_text = read_file(ty_file)

# ------------------------------
# LLM Helpers
# ------------------------------
def summarize_text(client, model: str, text: str, label: str) -> str:
    prompt = f"Metni 10-12 maddeyle kÄ±sa, Ã¶z ve bilgi kaybÄ± olmadan Ã¶zetle. BaÅŸlÄ±k: {label}.\n\nMetin:\n{text[:12000]}"
    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "KÄ±sa ve bilgi kaybÄ± olmadan Ã¶zetleyen bir yardÄ±mcÄ± yazarsÄ±n."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"(Ã–zetlenemedi: {e})"

def generate_analysis(client, model: str, system_prompt: str, user_prompt: str, temperature: float = 0.3) -> Dict[str, Any]:
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=temperature,
        response_format={"type": "json_object"},
    )
    content = resp.choices[0].message.content
    try:
        data = json.loads(content)
    except Exception:
        data = {"raw": content}
    return data

# ------------------------------
# Generate
# ------------------------------
if st.button("ðŸ§  Analizi Ãœret", type="primary"):
    if client and questions and any(a.get("answer") for a in answers) and (edu_text and tech_text):
        with st.spinner("Analiz hazÄ±rlanÄ±yorâ€¦"):
            edu_summary = summarize_text(client, model, edu_text, "EÄŸitim Ã–zeti")
            ty_summary = summarize_text(client, model, tech_text, "Teknik & YÃ¶ntemler Ã–zeti")

            schema = ANALYSIS_SCHEMA.copy()

            system_prompt = SYSTEM_PROMPT
            user_prompt = USER_TEMPLATE.format(
                education_summary=edu_summary,
                techniques_summary=ty_summary,
                questions_json=json.dumps(questions, ensure_ascii=False),
                answers_json=json.dumps(answers, ensure_ascii=False),
                json_schema=json.dumps(schema, ensure_ascii=False),
            )

            data = generate_analysis(client, model, system_prompt, user_prompt, temperature)

            data.setdefault("meta", {})
            data["meta"].setdefault("education_title", q_meta.get("education_title", "EÄŸitim"))
            data["meta"]["num_answers"] = len([a for a in answers if a.get("answer")])
            data["meta"]["language"] = language

            st.session_state["analysis_data"] = data
    else:
        st.warning("LÃ¼tfen tÃ¼m dosyalarÄ± ve yanÄ±tlarÄ± girin.")

# ------------------------------
# Show Output
# ------------------------------
if st.session_state.get("analysis_data"):
    st.markdown("---")
    st.subheader("ðŸ“Ž Analiz Sonucu")
    data = st.session_state["analysis_data"]

    try:
        jsonschema_validate(data, ANALYSIS_SCHEMA)
    except Exception as e:
        st.warning(f"Åžema doÄŸrulamasÄ± uyarÄ±sÄ±: {e}")

    meta = data.get("meta", {})
    st.write(f"**EÄŸitim:** {meta.get('education_title', 'EÄŸitim')} Â· **YanÄ±t sayÄ±sÄ±:** {meta.get('num_answers', 0)}")

    st.text_area("GA Ãœslubunda Sistem Analizi", value=data.get("ga_style_narrative", ""), height=500)

    if data.get("safety_notes"):
        st.info(data.get("safety_notes"))

    pretty = json.dumps(data, ensure_ascii=False, indent=2)
    st.download_button("ðŸ“¥ analysis.json", data=pretty, file_name="analysis.json", mime="application/json")
